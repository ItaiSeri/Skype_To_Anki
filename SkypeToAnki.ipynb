{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import fasttext\n",
    "import time\n",
    "from pathlib import Path\n",
    "from itertools import compress\n",
    "from googletrans import Translator\n",
    "from pycountry import languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Translator() #googletrans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local location of trained model for language detection. Explained in details here::\n",
    "https://fasttext.cc/docs/en/language-identification.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "fasttext_model_path=r\"C:\\Users\\Itai\\Anaconda3\\Lib\\site-packages\\fasttext\\lid.176.bin\" \n",
    "fasttext_model = fasttext.load_model(fasttext_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create functions that will be used in main function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_lang(character,src_lang):\n",
    "    lang_list=[]\n",
    "    predictions = fasttext_model.predict(character,k=5,threshold=0.7)[0]\n",
    "    for pred in predictions:\n",
    "        pred=pred.replace('__label__','')\n",
    "        if languages.get(alpha_2=pred) is not None:\n",
    "            lang_list.append(languages.get(alpha_2=pred).name)\n",
    "    return src_lang in lang_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SplitAndTrim(text,trim=True, split_del='\\n'): \n",
    "    if trim == True:\n",
    "        return text.replace(\" \",\"\").split(split_del)\n",
    "    else:\n",
    "        return text.split(split_del)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create main function.\n",
    "This parses json file into csv file that can be imoported into Anki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Skype2Anki(Skype_file_path,contact_list,src_lang,trim=True, split_del='\\n',start_date='2000-01-01',end_date='2099-01-01'):\n",
    "\n",
    "\n",
    "    start = time.time()\n",
    "    #Read conversations column from Skype's Json file, then normalize. I.E Break up Series to df with meaningful columns\n",
    "    normalized=pd.json_normalize(pd.read_json(Skype_file_path,encoding='utf-8').conversations)\n",
    "    \n",
    "    #Convert the MessageList of every contact to df, then concat all of them into one df \n",
    "    df=pd.concat(normalized.MessageList[normalized.displayName.isin(contact_list)].apply(lambda x: pd.DataFrame(x)).tolist())\n",
    "       \n",
    "    #Convert originalarrivaltime to datetime & filter df by datetime\n",
    "    df.originalarrivaltime=pd.to_datetime(df.originalarrivaltime)\n",
    "    df=df[(df['originalarrivaltime'] > start_date) & (df['originalarrivaltime'] < end_date)]\n",
    "    \n",
    "    #delete white spaces needs to be only in asian languages\n",
    "    df['content_trim_split']= df['content'].apply(lambda x: SplitAndTrim(x,trim, split_del))\n",
    "     #apply the function for every word\n",
    "    df['is_src_lang']= df['content_trim_split'].apply(lambda x: [check_lang(string,src_lang) for string in x])\n",
    "    #Delete lists where text is not in the source language\n",
    "    df['clean_content']= df[['content_trim_split','is_src_lang']].apply(tuple,axis=1).apply(lambda x: list(compress(x[0],x[1])))\n",
    "    \n",
    "    # Leave only rows with non empty list. \"not x\": True for empty list, False for not empty list\n",
    "    # Split rows with multiple lists to multiple rows (explode)\n",
    "    fltrd_df=df.clean_content[df['clean_content'].apply(lambda x: not x) ==False].explode().reset_index(drop=True) \n",
    "    \n",
    "    #Transle every row to destination language\n",
    "    Translation=fltrd_df.apply(lambda x: translator.translate(x).text)\n",
    "    #Get pronunciation of source language for every row\n",
    "    Pinyin=fltrd_df.apply(lambda x: translator.translate(x,dest=src_langgoogle_code).pronunciation)\n",
    "    Anki_CSV=pd.concat([fltrd_df,Translation,Pinyin],axis=1)\n",
    "    Anki_CSV.columns=['Source','Translation','Pinyin']\n",
    "    file=expath/'Anki_CSV.txt'\n",
    "    file.unlink(missing_ok=True) #Delete file if exists\n",
    "    Anki_CSV.to_csv(file, index=None, mode='a')\n",
    "    end = time.time()\n",
    "    runtime= end - start\n",
    "    print('CSV file created after '+ str(runtime) + ' seconds.\\nLocation: ' +str(expath/'Anki_CSV.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define variables that will be used with Skype2Anki() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_langgoogle_code= 'zh-CN' #code list can be found here: https://cloud.google.com/translate/docs/languages\n",
    "src_lang='Chinese'\n",
    "start_date='2000-01-01'\n",
    "end_date='2099-01-01'\n",
    "Skype_file_path=Path(r\"F:\\Dowloads\\8_itai.seri_export\\messages.json\")\n",
    "expath=Path(\"F:/Dowloads\")\n",
    "contact_list=['Anne Wu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Json Skype file before proccesing & cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['userId', 'exportDate', 'conversations'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>exportDate</th>\n",
       "      <th>conversations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8:itai.seri</td>\n",
       "      <td>2020-06-25T03:41</td>\n",
       "      <td>{'id': '48:calllogs', 'displayName': None, 've...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8:itai.seri</td>\n",
       "      <td>2020-06-25T03:41</td>\n",
       "      <td>{'id': '8:laiyi131418', 'displayName': 'Ruby',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8:itai.seri</td>\n",
       "      <td>2020-06-25T03:41</td>\n",
       "      <td>{'id': '28:concierge', 'displayName': 'Skype',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8:itai.seri</td>\n",
       "      <td>2020-06-25T03:41</td>\n",
       "      <td>{'id': '4:+393389369706', 'displayName': None,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8:itai.seri</td>\n",
       "      <td>2020-06-25T03:41</td>\n",
       "      <td>{'id': '4:+393337569170', 'displayName': None,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId        exportDate  \\\n",
       "0  8:itai.seri  2020-06-25T03:41   \n",
       "1  8:itai.seri  2020-06-25T03:41   \n",
       "2  8:itai.seri  2020-06-25T03:41   \n",
       "3  8:itai.seri  2020-06-25T03:41   \n",
       "4  8:itai.seri  2020-06-25T03:41   \n",
       "\n",
       "                                       conversations  \n",
       "0  {'id': '48:calllogs', 'displayName': None, 've...  \n",
       "1  {'id': '8:laiyi131418', 'displayName': 'Ruby',...  \n",
       "2  {'id': '28:concierge', 'displayName': 'Skype',...  \n",
       "3  {'id': '4:+393389369706', 'displayName': None,...  \n",
       "4  {'id': '4:+393337569170', 'displayName': None,...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pd.read_json(Skype_file_path,encoding='utf-8').columns)\n",
    "pd.read_json(Skype_file_path,encoding='utf-8').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file created after 24.50207257270813 seconds.\n",
      "Location: F:\\Dowloads\\Anki_CSV.txt\n"
     ]
    }
   ],
   "source": [
    "Skype2Anki(Skype_file_path,contact_list,src_lang,trim=True, split_del='\\n',start_date='2000-01-01',end_date='2099-01-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result - CSV file ready to be imported into Anki:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Translation</th>\n",
       "      <th>Pinyin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>我去大城市的电影院看电影。</td>\n",
       "      <td>I go to a movie theater in a big city to watch...</td>\n",
       "      <td>Wǒ qù dà chéngshì de diànyǐngyuàn kàn diànyǐng.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>下车</td>\n",
       "      <td>get off</td>\n",
       "      <td>Xià chē</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>你先坐五路车，然后转十路车。</td>\n",
       "      <td>You take the No. 5 car first, then transfer to...</td>\n",
       "      <td>Nǐ xiān zuò wǔ lù chē, ránhòu zhuǎn shí lù chē.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>五路车</td>\n",
       "      <td>Five-way car</td>\n",
       "      <td>Wǔ lù chē</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>我应该坐哪路车？</td>\n",
       "      <td>Which bus should I take?</td>\n",
       "      <td>Wǒ yīnggāi zuò nǎ lù chē?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>米饭</td>\n",
       "      <td>rice</td>\n",
       "      <td>Mǐfàn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>请来一盘饺子。</td>\n",
       "      <td>Please have a plate of dumplings.</td>\n",
       "      <td>Qǐng lái yī pán jiǎozi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>我还没试过中国菜。</td>\n",
       "      <td>I haven't tried Chinese food.</td>\n",
       "      <td>Wǒ hái méi shìguò zhōngguó cài.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>下课后我开始工作。</td>\n",
       "      <td>I started working after class.</td>\n",
       "      <td>Xiàkè hòu wǒ kāishǐ gōngzuò.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>程序员</td>\n",
       "      <td>programmer</td>\n",
       "      <td>Chéngxù yuán</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Source                                        Translation  \\\n",
       "0    我去大城市的电影院看电影。  I go to a movie theater in a big city to watch...   \n",
       "1               下车                                            get off   \n",
       "2   你先坐五路车，然后转十路车。  You take the No. 5 car first, then transfer to...   \n",
       "3              五路车                                       Five-way car   \n",
       "4         我应该坐哪路车？                           Which bus should I take?   \n",
       "..             ...                                                ...   \n",
       "61              米饭                                               rice   \n",
       "62         请来一盘饺子。                  Please have a plate of dumplings.   \n",
       "63       我还没试过中国菜。                      I haven't tried Chinese food.   \n",
       "64       下课后我开始工作。                     I started working after class.   \n",
       "65             程序员                                         programmer   \n",
       "\n",
       "                                             Pinyin  \n",
       "0   Wǒ qù dà chéngshì de diànyǐngyuàn kàn diànyǐng.  \n",
       "1                                           Xià chē  \n",
       "2   Nǐ xiān zuò wǔ lù chē, ránhòu zhuǎn shí lù chē.  \n",
       "3                                         Wǔ lù chē  \n",
       "4                         Wǒ yīnggāi zuò nǎ lù chē?  \n",
       "..                                              ...  \n",
       "61                                            Mǐfàn  \n",
       "62                          Qǐng lái yī pán jiǎozi.  \n",
       "63                  Wǒ hái méi shìguò zhōngguó cài.  \n",
       "64                     Xiàkè hòu wǒ kāishǐ gōngzuò.  \n",
       "65                                     Chéngxù yuán  \n",
       "\n",
       "[66 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('F:\\Dowloads\\Anki_CSV.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
